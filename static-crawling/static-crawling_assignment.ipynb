{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b13c723b",
   "metadata": {},
   "source": [
    "# 알라딘 도서 페이지 정적 크롤링\n",
    "알라딘 도서 페이지에서 데이터를 추출하면서 정적 크롤링을 복습합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479f1522",
   "metadata": {},
   "source": [
    "### 1. 필요한 라이브러리 설치 및 임포트\n",
    "먼저, 웹 크롤링을 위해 필요한 라이브러리들을 설치하고 임포트합니다.\n",
    "\n",
    "- bs4: BeautifulSoup 라이브러리는 HTML/XML 페이지를 파싱하여 데이터를 쉽게 추출할 수 있게 도와줍니다.\n",
    "- requests: HTTP 요청을 보내 웹 페이지의 HTML을 받아오는 라이브러리입니다.\n",
    "- pandas: 데이터를 표 형태로 처리하고, csv 파일로 저장하는 데 사용됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b008a7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install bs4\n",
    "!pip install requests\n",
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4697a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "08e89dd0",
   "metadata": {},
   "source": [
    "### 2. HTML 페이지 불러오기 및 파싱\n",
    "이제 웹 페이지를 불러와서 HTML을 파싱하여 필요한 데이터를 추출하는 작업을 시작합니다.\n",
    "\n",
    "- requests.get(url): 지정한 URL에 HTTP GET 요청을 보냅니다.\n",
    "- BeautifulSoup(html, 'html.parser'): 응답 받은 HTML을 BeautifulSoup을 사용해 파싱합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a0864e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\"\"\"\n",
    "TODO\n",
    "1. requests 라이브러리로 url을 받아옵니다.\n",
    "2. Beautifulsoup로 html 문서를 파싱합니다.\n",
    "\"\"\"\n",
    "\n",
    "# 알라딘 베스트셀러 페이지 URL\n",
    "url = \"https://www.aladin.co.kr/shop/common/wbest.aspx?BestType=Bestseller&BranchType=1&CID=0&page=1&cnt=1000&SortOrder=1\"\n",
    "response =  # 요청 보내기\n",
    "html =  # 응답 받은 HTML 문서\n",
    "soup = # BeautifulSoup으로 파싱\n",
    "soup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d30a367",
   "metadata": {},
   "source": [
    "### 3. 특정 HTML 요소 선택\n",
    "크롤링할 HTML 요소를 선택하기 위해 CSS 선택자를 사용하여 데이터를 추출합니다.\n",
    "\n",
    "- soup.select_one(): CSS 선택자를 사용하여 첫 번째 일치하는 요소를 선택합니다.\n",
    "- tree: 선택된 HTML 요소(첫 번째 단락)에 대한 정보를 담고 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4a05e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = \n",
    "tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bff8f90",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b42640f2",
   "metadata": {},
   "source": [
    "### 4. 정보 추출: 제목, 링크, 할인가, 별점\n",
    "선택한 HTML 요소에서 원하는 데이터를 추출합니다.  \n",
    "- title_tag.text: title_tag 요소에서 텍스트(제목)를 추출합니다.\n",
    "- title_tag.attrs['href']: title_tag 요소에서 링크를 추출합니다.\n",
    "- price_tag.text, review_tag.text : 각각 할인가, 별점을 추출합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09170331",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제목과 링크 추출\n",
    "title_tag = \n",
    "title_tag.text, title_tag.attrs['href']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3cf46f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 할인가와 별점 추출\n",
    "price_tag =\n",
    "review_tag =\n",
    "price_tag.text, review_tag.text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1079f8b1",
   "metadata": {},
   "source": [
    "### 5. 한 페이지에서 모든 도서 정보 추출\n",
    "한 페이지에 여러 도서가 있을 때, 모든 도서의 정보를 추출합니다.\n",
    "\n",
    "- soup.select(): 여러 개의 요소를 선택하여 리스트로 반환합니다.\n",
    "- 각 질문에 대해 for 루프를 돌며 제목, 링크, 할인가, 별점을 추출합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367a56a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "TODO\n",
    "위 코드를 기반으로 빈칸을 채워 완성하세요.\n",
    "\n",
    "참조 : try-except문을 통해 원하는 정보가 없는 도서의 경우를 넘어가도록 합니다.\n",
    "웹사이트의 정보는 늘 균일하지 않기에 크롤링에서 예외처리는 중요합니다.\n",
    "\"\"\"\n",
    "\n",
    "trees = \n",
    "for tree in trees:\n",
    "    try:\n",
    "        title = \n",
    "        title_text = title.text\n",
    "        title_link = title.attrs['href']\n",
    "        price = \n",
    "        review = \n",
    "        print(title_text, title_link, price, review)\n",
    "    except: continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab0663d",
   "metadata": {},
   "source": [
    "### 6. 여러 페이지 크롤링\n",
    "페이지를 변경하면서 여러 페이지의 데이터 크롤링을 해봅시다.\n",
    "\n",
    "- for page_num in range(1, 4): 1페이지부터 3페이지까지 순차적으로 크롤링합니다.\n",
    "- 각 페이지에서 데이터를 추출하여 datas 리스트에 추가하고, 이를 pandas DataFrame으로 변환하여 csv 파일로 저장합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "940ebef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47cbd64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "TODO\n",
    "1. for loop을 통해 여러 페이지로 이동합니다.\n",
    "HINT : formatted string을 활용합니다.\n",
    "2. 내부 for loop에서 위 코드에서 실행했던 한 페이지에서 도서 정보 모으기를 실행합니다.\n",
    "3. DataFrame에 정보를 저장합니다.\n",
    "\"\"\"\n",
    "\n",
    "datas = []\n",
    "for page_num in range(1, 4):\n",
    "    url = \n",
    "    response = \n",
    "    html = \n",
    "    soup = \n",
    "    trees = \n",
    "    for tree in trees:\n",
    "        try:\n",
    "            title =\n",
    "            title_text = title.text\n",
    "            title_link = title.attrs['href']\n",
    "            price = \n",
    "            review = \n",
    "        except: continue\n",
    "\n",
    "df = \n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e983daee",
   "metadata": {},
   "source": [
    "### 7. 결과 저장\n",
    "위의 크롤링한 데이터를 csv 파일로 저장합니다.\n",
    "\n",
    "- df.to_csv(): 추출한 데이터를 csv 파일로 저장합니다. index=False를 설정하여 인덱스를 제외하고 저장합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e42471",
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv 파일로 저장해 봅시다.\n",
    "df.to_csv()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
